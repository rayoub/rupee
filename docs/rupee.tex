\documentclass[a4,center,fleqn]{NAR}

\usepackage{textcomp}
\usepackage{lmodern}
\usepackage{gensymb}
\usepackage{booktabs}

% Enter dates of publication
\copyrightyear{2018}
\pubdate{?? ?????? ????}
\pubyear{????}
\jvolume{??}
\jissue{??}

%\articlesubtype{This is the article type (optional)}

\hbadness=99999

\newcommand{\head}[1]{\textnormal{\textbf{#1}}}

\newcommand{\ca}{$\alpha$-carbon\xspace}
\newcommand{\cas}{$\alpha$-carbons\xspace}

\begin{document}

\title{Article title}

\author{%
Ronald Ayoub\,$^{1,}$%
\footnote{To whom correspondence should be addressed.
Email: ronaldayoub@mail.umkc.edu},
Yugyung Lee\,$^{1}$}

\address{%
$^{1}$
School of Computing and Engineering, 
University of Missouri at Kansas City,
5110 Rockhill Road,
Kansas City, MO 64110, USA}

% Affiliation must include:
% Department name, institution name, full road and district address,
% state, Zip or postal code, country

\history{%
Received ?????? ??, ????;
Revised ?????? ??, ????;
Accepted ?????? ??, ????}

\maketitle

\begin{abstract}
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text.
\end{abstract}

\section{INTRODUCTION}

Proteins represent the functional end-product within the central dogma of molecular biology \cite{Crick1970}.
As such, understanding protein structure is a central goal within structural bioinformatics. 
Protein structure determination, prediction, alignment, and search all serve to advance this understanding. 
Below, we present our approach to a fast, scalable, and purely geometric protein structure search we refer to with the acronym of \emph{RUn Position Encoded Encodings} of residue descriptors (RUPEE).

Given a protein domain identifier, whole chain identifier or an uploaded file, RUPEE can search for matches among domains defined in SCOPe 2.07 \cite{Fox2013}, CATH v4.2 \cite{Orengo1997}, ECOD develop210 \cite{Cheng2014}, or else among whole chains defined in the PDB.
In contrast to currently available protein structure searches, RUPEE is able to search either of these databases using any identifier. 
For instance, you can search SCOPe using a CATH domain identifier. 

RUPEE has two modes of operation, fast and top-aligned. 
Fast mode is significantly faster than all other protein structure searches discussed below but at the expensive of accuracy.
Despite this, we will show that the accuracy of RUPEE in fast mode is not far below that of the best available structure searches. 
On the other hand, the accuracy and response times of RUPEE in top-aligned mode are comparable to currently available protein structure searches that are commonly considered fast. 

Besides our approach to protein structure search, we introduce a polar plot for torsion angles that may have wider applicability in the study of protein structure. 
Further, the \emph{run position encoding} heuristic introduced below may have wider applicability to algorithms for character sequences containing long runs of repeats. 

We first discuss some related work to provide a context for our approach followed by a description of our method. 
We end with a comparison of results against the mTM-align structure search \cite{Dong2018}, the secondary structure matching (SSM) search \cite{Krissinel2004}, and the CATHEDRAL structural scan \cite{Redfern2007} available at the CATH website.

% **************************************************************
% Keep this command to avoid text of first page running into the
% first page footnotes
\enlargethispage{-65.1pt}
% **************************************************************

\section{RELATED WORK}

Pairwise alignment involves finding a set of spatial rotations and translations for two protein structures that minimizes a distance metric. 
Most commonly, the root mean squared deviation (RMSD) between \cas of aligned residues is minimized.

The typical use case of aligning one protein structure to another does not impose tight response time requirements. 
For this reason, pairwise alignments can focus on accuracy. 
On the other hand, a protein structure search can involve thousands of comparisons and accuracy is often balanced against speed. 
In this case, pairwise alignment is still useful for evaluating the results of a search, and this is the approach we take. 

For pairwise alignment, Combinatorial Extensions (CE) \cite{Shindyalov1998} and FATCAT \cite{Ye2003} are among the most popular tools, representing rigid and flexible protein alignments, respectively. 
CE performs a rigid alignment in order to minimize RMSD and FATCAT allows for a constrained number of twists in the protein chain in order to find a more flexible alignment before minimizing RMSD.

Whereas pairwise structure alignments only depend on the sequence of \ca coordinates, protein structure searches often introduce a further dependence on the sequence order of amino acids.
This approach often takes the form of clustering proteins based on sequences and pre-calculating results for pairwise alignments among cluster representatives. 
Then, these pre-calculated results are used for filtering the number of structures used for comparisons against a query protein.
The exact formula for combining the use of representatives and pre-calculated results varies from system to system.
However, all systems using this approach share the same disadvantage, an indirect dependence on amino acid sequences. 
In the absence of a reliance on sequence representatives and pre-calculated results, and without sacrificing accuracy, response times suffer greatly, often taking upwards of an hour for queries to complete. 

For protein structure searches, VAST \cite{Gilbrat1996} and the FATCAT server \cite{Ye2004} are among the most popular. 
Nonetheless, these searches are slow in comparison to mTM, SSM, and CATHEDRAL when pre-calculated results are not used. 
If given a known protein domain, VAST can return structural neighbors in seconds using pre-calculated results. 
However, if uploading a PDB file where pre-calculated results are not used, response times for VAST can exceed 30 minutes. 
Similarly, the FATCAT server, that does not use pre-calculated results, can take over an hour to send results for a search against PDB-90 representatives \cite{Prlic2010}. 

The PhyreStorm server \cite{Mezulis2016} provides another notable protein structure search.
Here too, it depends on PDB pre-calculated pairwise comparisons among PDB-40 cluster representatives \cite{Prlic2010}. 
Notably, PhyreStorm returns good results within minutes based on an uploaded PDB file. 

Given the above, there remains a need for a purely geometric protein structure search.
For the serendipitous exploration of relations between protein structures performed in the trenches, this search should be fast. 
Moreover, with a $~10\%$ yearly growth rate of solved structures deposited in the PDB \cite{gkw1000}, this search should be scalable. 
At a minimum, RUPEE takes a significant step in this direction as will be shown below. 

\section{METHODS}

Broadly, we define a linear encoding of protein structure and convert this linear encoding into a bag of features. 
Min-hashing and locality sensitive hashing (LSH), techniques drawn from big-data, are then applied to implement a protein structure indexing method that serves as the foundation for both RUPEE operating modes, fast and top-aligned. 

Protein structure searches that use linear encodings are not unique \cite{Carpentier2005,Daniluk2011,Ritchie2012}.
The novelty of our approach lies in its remarkable performance given its simplicity. 
Additionally, elements of our approach can be isolated and found to be useful in their own right. 

\subsection{Regions of Torsion Angles}

Our first step towards a linear encoding of protein structure is to identify separable regions of permissible torsion angles,
but first we introduce a new plot of torsion angles better suited to this effort. 

\begin{figure*}[t]
\centering
\includegraphics{combined_torsion}
\caption{Ramachandran plot (right) and polar plot (left) of randomly sampled torsion angles}
\label{fig:combined_torsion}
\end{figure*}

Despite their utility and familiarity, Ramachandran plots \cite{Ramachandran1968} represent angular data using a square plot better suited for scalar data.
This leads to the unwieldy arrangement where the top part of the plot is continuous with the bottom and the left is continuous with the right. 

To identify regions of torsion angles, we randomly sampled 10,000 residues from high-resolution CATH s35 representatives to account for precision and redundancy, respectively. 
A Ramachandran plot of the sampled torsions angles is shown to the left in \figurename~\ref{fig:combined_torsion}. 
As can be seen, a single cluster of residues, consisting primarily of $\beta$-strands, appears at all 4 corners of the Ramachandran plot.

This continuity problem was partially addressed in \cite{Karplus2010} using \emph{wrapped} and \emph{mirrored} plots. 
Both wrapped and mirrored plots take advantage of the sparsely populated areas of the Ramachandran plot at $\phi = 0\degree$ and $\psi = -120\degree$.
However, with larger samples of torsion angles, the area at $\psi = -120\degree$ becomes less sparse. 
The use of a polar plot resolves this elegantly by only requiring one break in continuity at $\phi = 0\degree$. 

To the right in \figurename~\ref{fig:combined_torsion}, we plot the same torsion angles appearing in the Ramachandran plot using a polar plot. 
In this plot, $\phi$ corresponds to the radius $r$ and $\psi$ corresponds to the angle $\theta$ in traditional polar plots. 
Notice the residues appearing at the 4 corners of the Ramachandran plot now appear in one continuous region of the polar plot centered at $\phi = \pm180\degree$ and $\psi = \pm180\degree$. 

\subsection{Linear Encoding of Protein Structure}

The polar plot described above is used to define torsion angle regions for each secondary structure assignment. 
The eight DSSP secondary structure assignment codes defined in \cite{Kabsch1983} divide into three groups in which torsion angle regions are roughly the same: `G',`H',`I', and `T' corresponding to $3_{10}$-helix, $\alpha$-helix, $\pi$-helix, and turn, respectively; `E' and `B' corresponding to $\beta$-strand and $\beta$-bridge, respectively; and `S' and `C' corresponding to bend and coil, respectively.

\begin{figure*}[tb]
\begin{center}
\includegraphics{regions}
\end{center}
\caption{Polar plots of randomly sampled torsion angles with designated descriptors for region and DSSP code combinations}
\label{fig:regions}
\end{figure*}

Polar plots for each group of DSSP assignment codes along with defined regions and descriptor designations are shown in \figurename~\ref{fig:regions}, with the exception of turns and bridges, which receive descriptors 11 and 12, respectively. 
For each polar plot, there are well-defined continuous regions of torsion angles that remain continuous in the plots. 
The only exception is found in the bends and coil plot at $\psi = 60\degree$ between $\phi = -180\degree$ and $\phi = 0\degree$.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in,keepaspectratio]{1nycA00}
\end{center}
\caption{$\beta$-turn-$\beta$ motif from CATH domain 1nycA00}
\label{fig:beta_turn}
\end{figure}

As an example of our linear encoding, we apply our method to the $\beta$-turn-$\beta$ motif shown in \figurename~\ref{fig:beta_turn}.
The corresponding sequence of residue descriptors is shown below.
\begin{gather}\label{E:descrseq} 
    [\, 5, 5, 5, 5, 5, 5, 7, 5, 11, 11, 5, 5, 5, 5, 5, 5 \,]
\end{gather}

\subsection{Bag representation of protein structure}

Once a linear encoding for a protein structure is obtained, it needs to be further transformed into a representation suitable for fast and scalable similarity comparisons to other structures.
The processing of text documents within Information Retrieval~(IR) has long been used to satisfy these requirements using bag representations.
There are two distinct categories of representations for documents, syntactic and semantic, and much of the research applying IR to protein structure search has focused on the latter \cite{Aungand2004,Zhang2010,Budowski2010}. 

We have adapted the syntactic approach to document similarity, often referred to as shingling \cite{Broder1997a}, to our linear encoding of protein structure. 
We transform a linear sequence of descriptors into a multiset of shingles consisting of 4 consecutive descriptors.
The overlap between shingles ensures some of the order information within the original sequence is preserved in the bag. 

By shingling, we obtain a multiset of ordered lists from an ordered list of numbers. 
As an example, the sequence in (\ref{E:descrseq}) is transformed into the following bag of shingles. 
\begin{align}\label{E:shinglebag}
    \begin{split}
        \{\,&[5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 7] \\
            & [5, 7, 5], [7, 5, 11], [5, 11, 11], [11, 11, 5], [11, 5, 5] \\
            & [5, 5, 5], [5, 5, 5], [5, 5, 5], [5, 5, 5] \,\}
    \end{split}
\end{align}

Next, each shingle $s$ is hashed to an integer as shown in~(\ref{E:hashdef}). 
The hash function used is a simplification of the hash function used in the Rabin-Karp algorithm \cite{Karp1987}.
The prime number $13$ is used as the base since it is large enough to spread the descriptor values out in hash space without collisions. 
\begin{gather}\label{E:hashdef}
    s_{hash} = s_1 \times 13^2 + s_2 \times 13 + s_3
\end{gather}
Subsequently, the multiset in (\ref{E:shinglebag}) becomes the following bag of integers.
\begin{align}\label{E:hashbag}
    \begin{split}
    \{\,&915, 915, 915, 915, 917, 941, 1259 \\
        &999, 2007, 1929, 915, 915, 915, 915 \,\}
    \end{split}
\end{align}

This final step completes the transformation of an ordered list of descriptors to a multiset of integers that still retains some of the order information present in the original list. 

Notice in (\ref{E:hashbag}) the value 915, corresponding to the shingle $[ 5, 5, 5 ]$, occurs frequently indicating the presence of $\beta$-strands. 
Since most proteins are dominated by regular secondary structure, the abundance of shingles for $\beta$-strands as well as the three types of helices, end up dominating comparisons. 
Moreover, since shingles are limited in length, this situation allows for structures with many short $\beta$-strands to match structures with fewer long $\beta$-strands.
The same situation applies to helices. 

To address this lack of specificity, we introduce a heuristic we call \emph{run position encoding} (RPE). 
To distinguish between short and long runs, thereby increasing the specificity of the shingles, we add a factor of $10^5$ to each shingle hash as a function of the first residue's position in a run $i$. 
\begin{gather}
    runfactor(i) = 
    \begin{cases}
        i               &\text{if $i < \lfloor l/2 \rfloor$}\\
        l - i - 1       &\text{otherwise} 
    \end{cases}
\end{gather}
where $i$ is zero-based and $l$ is the length of the run. 
Multiplying by $10^5$ places the run factor as the left-most digit in the hash to avoid interference with the digits provided by the hash in (\ref{E:hashdef}).
This placement is also convenient for visual inspection, since the run factor is isolated as the left-most digit. 

The run factors for the sequence in (\ref{E:descrseq}) are
\begin{align}
    [\, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0 \,].
\end{align}
Applied to the bag of integers in (\ref{E:hashbag}) gives
\begin{align}\label{E:rpebag}
    \begin{split}
    \{\,&00915, 10915, 20915, 20915, 10917, 00941, 01259 \\
        &00999, 02007, 01929, 00915, 10915, 20915, 20915 \,\}
    \end{split}
\end{align}
where the leading zero run factors are shown for clarity. 

This pyramidal approach preserves matches at the boundaries between secondary structure runs and loops that would not otherwise be preserved in the presence of differences in run lengths of one or more. 

To see why RPE run factors are calculated at the descriptor level and factored in at the shingle level, consider shingling a list of RPE run factors themselves, which mirrors applying them at the descriptor level. 
\begin{align*}
    &\text{The sequence of RPE factors} \\
    &\qquad[\, 0, 1, 2, 3, 2, 1, 0 \,] \text{ becomes} \\
    &\qquad\{\, [0, 1, 2, 3], [1, 2, 3, 2], [2, 3, 2, 1], [3, 2, 1, 0] \,\} \\
    &\text{and with one less element} \\
    &\qquad[\, 0, 1, 2, 2, 1, 0 \,] \text{ becomes} \\
    &\qquad\{\, [0, 1, 2, 2], [1, 2, 2, 1], [2, 2, 1, 0] \,\}
\end{align*}
Notice above, there is not a single match for this one-off difference in run length.
Now consider shingling a list of RPE factors, but this time all elements in the shingle are set equal to the first element in the shingle, which mirrors applying them at the shingle level. 
\begin{align*}
    &\text{The sequence of RPE factors} \\
    &\qquad[\, 0, 1, 2, 3, 2, 1, 0 \,] \text{ becomes} \\
    &\qquad\{\, [0, 0, 0, 0], [1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3] \,\} \\
    &\text{and with one less element} \\
    &\qquad[\, 0, 1, 2, 2, 1, 0 \,] \text{ becomes} \\
    &\qquad\{\, [0, 0, 0, 0], [1, 1, 1, 1], [2, 2, 2, 2] \,\}
\end{align*}
In this latter case, a one-off difference in run length results in one less shingle match while still serving to increase the specificity of the shingles. 

Now that we have a representation of a protein structure as a bag of integers, similarity between any two structures $a$ and $b$ is defined as the Jaccard similarity \cite{Levan1971} for multisets,
\begin{align}
    J(a,b) = \frac{\sum_i min(a_i, b_i)}{\sum_i max(a_i,b_i)}\text{,}
\end{align}
where $i$ ranges over all possible shingle hashes $s_i$ and $a_i$ and $b_i$ give the counts of shingle hash $s_i$ in structures $a$ and $b$, respectively. 

\subsection{Min-hashing and LSH}

In IR, the bag of shingles representation of documents is used in the near dupe clustering of documents \cite{Broder1997b}.
One application of near dupe clustering is in the review stage of Electronic-Discovery \cite{Joshi2008}, which is the most expensive stage in a discovery process. 
Often millions of documents must be examined by a staff of attorneys to make a reasonable effort at providing all documents relevant to the discovery request. 
Grouping documents into near dupe clusters and assigning all documents within a cluster to a single reviewer reduces duplication of effort. 

In the case of near dupe clustering, each document must be compared to every other document in the collection, taking quadratic time.
For this task, min-hashing \cite{Broder1998} and locality sensitive hashing (LSH) \cite{Indyk1998} can be combined to reduce this to subquadratic time. 
Although we do not near dupe cluster domains, we can still leverage the techniques of min-hashing and LSH to speed up protein structure search by a large constant factor.

Min-hashing is used to randomly select items from a set of items by repeatedly randomly hashing the items, sorting the hashes into a list, and then selecting the minimum item in each permuted list.
If the same random permutation of items is performed on each set of items in a collection, the key result is that the probability of matching min-hashes is equal to the Jaccard similarity \cite{Broder1998}.
In order to approximate the Jaccard similarity for a given pair of sets, a sufficient number of min-hashes must be obtained. 

In our case, the items are bags of shingle hashes for protein structures from which we obtain 99 min-hashes as described in \cite{Rajaraman2012}. 
Given the key result above, the Jaccard similarity can now be approximated by the proportion of matching min-hashes. 

Next, we use the LSH banding technique as described in \cite{Rajaraman2012}.
The key result of the banding technique is that if \emph{any} band positions are a match for a given pair of structures, the probability that a specific similarity threshold has been met can be calculated. 
We use 33 bands of 3-min-hashes where the probability of a Jaccard similarity of 60\% or greater is approximately 99\%. 
Banding allows the problem of finding similar items to be parallelized across bands since all that is needed for a match is a single band match. 

Together, min-hashing and LSH provide the foundation for both operating modes of RUPEE, fast and top-aligned.

\subsection{Operating modes}

RUPEE provides 2 operating modes, fast and top-aligned. 
Each operating mode builds on the results provided by the min-hashing and LSH system described above. 
When a structure search is executed in either mode, a number of concurrent tasks are executed corresponding to the number of bands used for LSH. 
These concurrent tasks identify candidate matches based on a single band match and then validate the matches based on a comparison of min-hashes. 

In fast mode, the top 8,000 matches are obtained along with the original gram sequences defined for the structures.
A further validation is done by performing a longest common subsequence (LCS) analysis of the matched gram sequences and adjusting the Jaccard similarity scores accordingly.
This step accounts for possible gram matches among pairs of structures that are out of order since the min-hashing and LSH techniques themselves do not consider the order of the gram matches.
The final step of fast mode is to sort the matches based on the adjusted scores and return the results. 

Top-aligned is an additional step following fast mode. 
First, unoptimized CE alignments are performed on the top 2,000 matches obtained from fast mode. 
Then optimized CE alignments are performed on the top 400 matches and these are finally returned sorted either by RMSD or TM-Score. 
Currently, top-aligned is a simple layer following fast mode that establishes RUPEE fast mode as an effective filtering method that contains in its top 2,000 results enough good matches to compete with the best available structure searches. 

\section{RESULTS}

Protein structure searches can be evaluated using pairwise alignment scores or by comparison of results against the hierarchy of a protein structure classification database.
The RMSD of aligned residues is widely used in evaluations but is not perfectly suited to full-length comparisons between structures since distances between unaligned residues are not factored into the score.
On the other hand, the TM-score \cite{Zhang2004} takes all residues into account. 
Among protein structure classification databases for which corresponding structure searches exist, SCOPe \citep{Fox2013} and CATH \citep{Orengo1997} are the most popular. 

For our results, we have created 3 benchmarks (scop\_d360, scop\_d62, and cath\_d99) for pairwise evaluations to mTM, SSM, and CATHEDRAL, respectively.
scop\_d360 is derived from the d500 benchmark used in \cite{Dong2018} filtered for domains for which mTM returns 100 or more results defined in SCOPe 2.07. 
Similarly, scop\_d62 is derived from the d500 benchmark filtered for domains defined in SCOP 1.73 for which SSM returns 50 or more results.  
In keeping with our description of RUPEE in \cite{Ayoub2017}, the cath\_d99 benchmark contains 99 superfamily representatives from the top 100 most diverse superfamilies defined in CATH v4.2 for which CATHEDRAL returns results in less than 12 hours. 

We perform pairwise evaluations to ensure the fairness of our comparisons. 
First, For domain searches, SSM is working with the SCOP 1.73 database, so accordingly we operate RUPEE on SCOP 1.73 domains to ensure RUPEE does not have more domains to work with for scoring and precision evaluations. 
Second, mTM is updated to work with SCOP 2.07 domain definitions but still retains domains from 2.06 that have since been redefined either through mergers or splits in 2.07. 
On the other hand, CATHEDRAL presents no such challenges but still requires a separate benchmark since it is working with a distinct hierarchy, CATH v4.2. 

All benchmark definitions can be found in the supplementary material. 

\subsection{Scoring}

\figurename~\ref{fig:combined_scoring_ce} shows average cumulative values for each ranked result averaged over all searches.
Both RMSD and TM-score values are shown, provided as outputs from CE pairwise alignments. 
References lines are drawn in the TM-score plot in \figurename~\ref{fig:combined_scoring_ce} at TM-scores of 0.5 and 0.17. 
A TM-score above 0.5 is a good predictor for whether or not two domains are in the same fold \cite{Xu2010}.
TM-scores greater than 0.17 are considered potentially meaningful whereas TM-scores less than 0.17 are considered to be due to random alignment \cite{Zhang2004}.

\begin{figure*}[tb]
\begin{center}
\includegraphics{combined_scoring_ce}
\end{center}
\caption{Evaluation of scoring from CE pairwise alignments}
\label{fig:combined_scoring_ce}
\end{figure*}

A figure similar to \figurename~\ref{fig:combined_scoring_ce} but using FATCAT for pairwise comparisons can be found in the supplementary material. 
The same relative relationships hold with only small variations. 

All of RUPEE fast and top-aligned, sorted by RMSD and TM-Score, perform better than SSM and CATHEDRAL.
The scoring in the cath\_d99 benchmark comparisons are notably lower than for the other two benchmarks. 
This is expected since CATHEDRAL only returns CATH s35 representatives and for this comparison RUPEE is filtered for s35 representatives to match. 
Given that the cath\_d99 benchmark is evaluated against representatives, there are fewer highly similar structures returned in the results. 

In our evaluation, mTM faired better than SSM and CATHEDRAL. 
For TM-Score, RUPEE and mTM are nearly identical. 
For RMSD, RUPEE does perform better than mTM but this can most likely be attributed to the fact that mTM only sorts by TM-Score. 
If mTM sorted by RMSD then we feel the results again would be nearly identical.
Nevertheless, it is worth noting that the initial LSH and min-hashing technique does not explicitly bias results towards one particular measure. 

\subsection{Precision}

\figurename~\ref{fig:combined_precision} shows precision (i.e. positive predictive value or PPV) averaged over all searches, where positive results are defined as domains with the same classification for the indicated hierarchy level as the query domain. 
Here, RUPEE is 
A plot of recall is unnecessary since \figurename~\ref{fig:combined_precision} provides precision at specific ranks for identical sets of searches. Hence, recall curves have the same relative relationships as those shown for precision. 

We should expect a structure search to have reasonable precision with respect to the hierarchy levels of the structure classification it is searching. 
However, it is not clear how to define reasonable. 
On the other hand, if precision is too high, the search provides little value beyond that provided by the structure classification hierarchy it is searching. 
That is, it would be sufficient for a search to return the best match and from their refer to the hierarchy. 

\begin{figure*}[tb]
\begin{center}
\includegraphics{combined_precision}
\end{center}
\caption{Something Something}
\label{fig:combined_precision}
\end{figure*}

Similar to scoring evaluations above, all of RUPEE fast and top-aligned, sorted by RMSD and TM-Score, perform better than SSM and CATHEDRAL.

\subsection{Response Times}

Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.

\begin{figure*}[tb]
\begin{center}
\includegraphics{combined_response}
\end{center}
\caption{Something Something}
\label{fig:combined_response}
\end{figure*}

Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text.

\section{DISCUSSION}

Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text.

\section{CONCLUSION}

Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text. Text. Text. Text. Text. Text. Text. Text. Text.
Text. Text. Text.

\subsubsection{Conflict of interest statement.} None declared.
\newpage

\nocite{Ayoub2017}
\nocite{BioJava2012}
\bibliography{rupee}
\bibliographystyle{NAR-natbib}

\end{document}
